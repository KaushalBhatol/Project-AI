<?php
$page_name = 'Advanatage and Disadvantage';
$metaDescription = '';
include 'compo/head.php';
include 'compo/Breadcrumbs.php';
?>
<!-- ======= Blog Single Section ======= -->
<section id="blog" class="blog">
    <div class="container" data-aos="fade-up">
        <div class="row">
            <div class="col-lg-12 entries">
                <article class="entry entry-single">
                    <div class="entry-img">
                        <img src="" alt="" class="col-lg-12 img-fluid">
                    </div>
                    <h2 class="entry-title">
                        Myths about Advanced Artificial Intelligence
                    </h2>
                    <div class="entry-content">
                        <h3>1. Superintelligence by the year 2100 is not possible.</h3>
                        <p>The reality about the possibility of superintelligence is that currently, we can't determine it. It may occur in decades, or centuries, or may never, but nothing is confirmed. There have been several surveys in which AI researchers have been asked how many years from now they think we will have human-scale AI with at least a 50% chance. All of these surveys have the same conclusion: The world's leading experts disagree, so we don't know. For example, in such a survey of AI researchers at the 2015 Puerto Rico AI conference, the (average) answer was by 2045, but some researchers estimated hundreds of years or more.</p>
                        <h3>2. I will replace all human jobs.</h3>
                        <p>It's certainly true that the advent of AI and automation has the potential to disrupt labour seriously - and in many situations, it is already doing just that. However, seeing this as a straightforward transfer of labour from humans to machines is a vast oversimplification.
                            With the development of AI, a revolution has come in industries of every sector, and people fear losing jobs with the increased development of AI. But in reality, AI has come up with more jobs and opportunities for people in every sector. Every machine needs a human being to operate it. However, AI has taken over some roles, but it reverts to producing more jobs for people.</p>
                        <h3>3. Super-intelligent computers will become better than humans at doing anything we can do</h3>
                        <p>As discussed above, AI can be divided into three types, Weak AI, which can perform specific tasks, such as weather Prediction. General AI; Capable of performing the task as a human can do, Super AI; AI capable of performing any task better than human.
                            At present, we are using weak AI that performs a particular task and improves its performance. On the other hand, general AI and Super AI are not yet developed, and researches are going on. They will be capable of doing different tasks similar to human intelligence. However, the development of such AI is far away, and it will take years or centuries to create such AI applications. Moreover, the efficiency of such AI, whether it will be better than humans, is not predictable at the current stage.</p>
                        <h3>4. AI does not require human intervention.</h3>
                        <p>People also have a misconception that AI does not need any human intervention. But the fact is that AI is not yet developed to take their own decisions. A machine learning engineer/specialist is required to pre-process the data, prepare the models, prepare a training dataset, identify the bias and variance and eliminate them, etc. Each AI model is still dependent on humans. However, once the model is prepared, it improves its performance on its own from the experiences.</p>

                        <h2>How can Artificial Intelligence be risky?</h2>

                        <p>Most of the researchers agree that super AI cannot show human emotions such as Love, hate or kindness. Moreover, we should not expect an AI to become intentionally generous or spiteful. Further, if we talk about AI to be risky, there can be mainly two scenarios, which are:</p>
                        <h3>1. AI is programmed to do something destructive:</h3>
                        <p>Autonomous weapons are artificial intelligence systems that are programmed to kill. In the hands of the wrong person, these weapons could easily cause mass casualties. Moreover, an AI arms race could inadvertently lead to an AI war resulting in mass casualties. To avoid being dissatisfied with the enemy, these weapons would be designed to be extremely difficult to "turn off," so humans could plausibly lose control of such a situation. This risk is present even with narrow AI but grows as levels of AI intelligence and autonomy increase.</p>
                        <h3>2. Misalignment between our goals and machines:</h3>
                        <p>The second possibility of AI as a risky technology is that if intelligent AI is designed to do something beneficial, it develops destructive results. For example, Suppose we ask the self-driving car to "take us at our destination as fast as possible." The machine will immediately follow our instructions. It may be dangerous for human lives until we specify that traffic rules should also be followed and we value human life. It may break traffic rules or meet with an accident, which was not really what we wanted, but it did what we have asked to it. So, super-intelligent machines can be destructive if they ask to accomplish a goal that doesn't meet our requirements.</p>
                    </div>
                </article><!-- End blog entry -->
            </div><!-- End blog entries list -->
        </div>
    </div>
</section><!-- End Blog Single Section -->